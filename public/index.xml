<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Think Regressively on Think Regressively</title>
    <link>https://thinkregressively.netlify.com/</link>
    <description>Recent content in Think Regressively on Think Regressively</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2018</copyright>
    <lastBuildDate>Sun, 15 Oct 2017 00:00:00 -0400</lastBuildDate>
    <atom:link href="/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Run a Tensorflow Model in a Non GPU Supported Computer</title>
      <link>https://thinkregressively.netlify.com/post/tensforflow/</link>
      <pubDate>Sun, 12 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://thinkregressively.netlify.com/post/tensforflow/</guid>
      <description>&lt;p&gt;Recently, I’ve been playing with the deep learning python package ‘tensorflow’. I ran a simple linear regression model and had some success. Tensorflow is great with unstructured data and image recognization problem. Therefore, it usually runs better in a GPU supported computer. However, given my model is rather simple and won’t need to rely on too much image processing power like GPU. I did it on my windows 7 professional/10 machine and it predicted some values for me. Below are the detailed walk-throughs:&lt;/p&gt;
&lt;div id=&#34;step-1-install-tensorflow-package-into-python&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;step 1: install tensorflow package into python&lt;/h3&gt;
&lt;p&gt;I use Pycharm- &lt;a href=&#34;https://www.jetbrains.com/pycharm/&#34;&gt;a Python IDE&lt;/a&gt; to install tensforflow which is really easy. Go to the settings of Pycharm and navigate to the ‘project interpreter’ tab and click on ‘+’ sign and search ‘tensorflow’ name and click ‘install’ button at the bottom. See below screenshot:&lt;img src=&#34;https://thinkregressively.netlify.com/static/img/install_tensorflow.JPG&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;step-2-load-a-clean-data-and-split-it-for-training-and-testing-data-using-sklearn&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;step 2: load a clean data and split it for training and testing data using sklearn&lt;/h3&gt;
&lt;p&gt;I’m loading a sample data set called ad_wx and convert some of my columns(feature candidates) to numeric data type for better building features for tensorflow. And you guessed it, ‘AVG_weedday4’,‘AVG_weedday5’ and ‘ad_unit’ will become my 3 features in my simple tensorflow model.&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;import pandas as pd
ad_wx=pd.read_csv(&amp;#39;ad-wx.csv&amp;#39;)
ad_wx[&amp;#39;AVG_weedday4&amp;#39;]=ad_wx[&amp;#39;AVG_weedday4&amp;#39;].astype(&amp;#39;int64&amp;#39;)
ad_wx[&amp;#39;AVG_weedday5&amp;#39;]=ad_wx[&amp;#39;AVG_weedday5&amp;#39;].astype(&amp;#39;int64&amp;#39;)
ad_wx[&amp;#39;ad_unit&amp;#39;]=ad_wx[&amp;#39;ad_unit&amp;#39;].astype(&amp;#39;str&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Next, I use sklearn.model_selection to split the data into training and testing dataset with testing dataset to be 30% of total data. clicks/impression is my target variable or predicting variable.&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;from sklearn.model_selection import train_test_split
x_data=ad_wx.drop(&amp;#39;clicks/impression&amp;#39;,axis=1)
y_data=ad_wx[&amp;#39;clicks/impression&amp;#39;]
X_train,X_test,y_train,y_test=train_test_split(x_data,y_data,test_size=0.3,random_state=100)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;step-3-build-feature-column-and-input-function-using-tensorflow-estimator-api&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;step 3: build feature column and input function using tensorflow estimator API&lt;/h3&gt;
&lt;p&gt;After we had training and testing data, we are ready to run the tensorflow model. To build a model in Tensorflow, we basically need to build a feature column list and input function to train the model. For features to be tensorflow ready, we need to convert them into the datatype that tensorflow can recognize. There are two functions that are commonly used to convert features. categorical_column_with_has_bucket() and numeric_column() are used to convert catgorical variable to tensorflow ready feature as well as numeric variables. Once done, you can throw them into a list.&lt;/p&gt;
&lt;p&gt;Regarding input function, you use your training data to train that input function by batch loadin them (see batch_size argument below) and iterate for n times (see num_epochs argument) with shuffling.&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;import tensorflow as tf
ad_unit=tf.feature_column.categorical_column_with_hash_bucket(&amp;#39;ad_unit&amp;#39;,hash_bucket_size=1000)
weed4=tf.feature_column.numeric_column(&amp;#39;AVG_weedday4&amp;#39;)
weed5=tf.feature_column.numeric_column(&amp;#39;AVG_weedday5&amp;#39;)
feat_col=[ad_unit,weed4,weed5]
input_func=tf.estimator.inputs.pandas_input_fn(x=X_train,y=y_train,batch_size=10,num_epochs=100,shuffle=True)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;step-4-predict-target-values-using-cpu-processing-patch&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;step 4: predict target values using CPU processing patch&lt;/h3&gt;
&lt;p&gt;After you are done with building the essential parts for the model, you can then build the model and train the data. After the model is built and trained, then you can use a prediction function to predict the target variables. prediction function is basically an input function that uses testing data. You use model.predict() to predict values. The output predicted numbers initially is a dictionary. You will need to convert it to a list so that you can extract the predicted value. After that’s done, you can write it out using numpy’s savetxt() function.&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;model=tf.estimator.LinearRegressor(feature_columns=feat_col)
model.train(input_fn=input_func,steps=500)
pred_fn=tf.estimator.inputs.pandas_input_fn(x=X_test,batch_size=len(X_test),num_epochs=100,shuffle=False)
predictions=list(model.predict(input_fn=pred_fn))
final_preds=[]
for pred in predictions:
    final_preds.append(pred[&amp;#39;predictions&amp;#39;][0])
    
import numpy as np
np.savetxt(&amp;#39;tf_predictions.csv&amp;#39;,final_preds,delimiter=&amp;#39;,&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;All the above steps are easy and simple except for the last part.To get the tensorflow model trained and render the predicted number, you usually need a GPU supported computer to run. However, there’s a work-around way for you to just use CPU computer to finish running the model.&lt;/p&gt;
&lt;p&gt;When you run your model, you will see the below error message:&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;2018-07-13 09:01:33.900329: I T:\src\github\tensorflow\tensorflow\core\platform\cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So the solution is to update the tensorflow binary for your CPU &amp;amp; OS using a wheel file. To install, use the below command in your command line prompt:&lt;/p&gt;
&lt;p&gt;&lt;em&gt;pip install –ignore-installed –upgrade ‘Download whl file’ &lt;/em&gt;&lt;/p&gt;
&lt;p&gt;The download url of the whl file can be found &lt;a href=&#34;https://github.com/lakshayg/tensorflow-build&#34;&gt;here&lt;/a&gt;. For windows, you will want to use &lt;a href=&#34;https://github.com/fo40225/tensorflow-windows-wheel/tree/master/1.8.0/py36/CPU/avx2&#34;&gt;this wheel file&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;After you download it, save it under your default command line directory. Mine is C:.shen and install it into your machine. Then you are good to go.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>User Susceptibility</title>
      <link>https://thinkregressively.netlify.com/project/user_susceptibility/</link>
      <pubDate>Sun, 01 Jul 2018 10:00:00 -0400</pubDate>
      
      <guid>https://thinkregressively.netlify.com/project/user_susceptibility/</guid>
      <description></description>
    </item>
    
    <item>
      <title>My Journey to Data Science</title>
      <link>https://thinkregressively.netlify.com/post/journey/</link>
      <pubDate>Sun, 01 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://thinkregressively.netlify.com/post/journey/</guid>
      <description>&lt;p&gt;If you have viewed my bio, you probably noticed that I don’t have a science or engineering background, so how come I end up with data scientist? Well, it turns out that you don’t need a science or engineering background to become a data scientist! Here’s my personal trajectory. I think it’s highly reproducible:)&lt;/p&gt;
&lt;p&gt;In Sep 2014, I was hired as a marketing research analyst by AccuWeather to work on AW’s new adventure: IoT or we call it emerging platform projects. The mission of the position is to assist the team to build weather based algorithm to power digital health, smart home and connected car apps/widgets. To complete the mission, we need data scientists and I was tasked to research on everything about data scientist as a job. From there, I found the below:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;data scientists got paid really well: above 11k annual salary&lt;/li&gt;
&lt;li&gt;data scientist job normally requires statistical, coding skills&lt;/li&gt;
&lt;li&gt;data scientist is on high demand&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;These findings triggered ‘Aha’ moment for me: I WANT TO BE A DATA SCIENTIST! But how?! At that time, there isn’t any data science major at any regular university. From what I’ve researched, almost all the data scientists are made into instead of graduated from. Therefore, I think there must a kit that contains everything that one needs to become a data scientist. Through coursera(MOOC website), I found Johns Hopkins Data Science Specialization course. It’s basically a 10-course specialization and not only teaches coding but also statistics. You can find more details &lt;a href=&#34;https://www.coursera.org/specializations/jhu-data-science&#34;&gt;here&lt;/a&gt;. I was so exited and fully sold and for the first time I spent money on some online course. Although the money later on got reimbursed by work, I was so determined that I think it will be a great investment. It turns out to be true because that way I was super movitated to finish a course each month and I also obtained a certificate from all the hard work I’ve done. To me, if I pay for something, I want to get my money worth. So I’m kind of person who only goes to buffet restaurant if I’m super hungry,lol.&lt;/p&gt;
&lt;p&gt;The Johns Hopkins Data Science specailization not only taught me R but also opened the door to a programming and statistical world. From there, I got to know all these stellar statistians/data scientists such as my instructor Roger Peng, Brian Caffo, Jeff Leek. From there, I started to pay attention to data science related podcasts, such as ‘Not So Standard Deviation(NSSD)’. From NSSD, I got to know Hilary Parker, a data scientist from StitchFix. From Roger Peng, I got to know ‘Effort Report’ a podcast that focuses on academia life. From NSSD,I got to know that Python is another major lanaguage that is acknlowledged unanimously among data science field. I then enrolled myself intot a 5-course python specialization taught by University of Michigan &lt;a href=&#34;https://www.coursera.org/specializations/data-science-python&#34;&gt;‘Applied Data Science in Python’&lt;/a&gt;.From there, I got to know a python focused podcast ‘Data Skeptics’. For a very long time, NSSD and DS are the only two data science related podcasts that kept me company and inspired me and pulled me closer and closer to the data science field, although nowadays I subscribed to many other data science and machine learning podcasts(see the list at the end). Podcasts are great to keep up with the latest news in the field and listen to the past expeirence and successful stories of varieties of data scientists as well as the data science projects.&lt;/p&gt;
&lt;p&gt;During this process, my title has changed from marketing research analyst to business intelligence analyst and to data scientist. At the same time, I’ve also served as an editor to a R newsletter called &lt;a href=&#34;https://rweekly.org/&#34;&gt;RWeekly&lt;/a&gt; and the social media chair of &lt;a href=&#34;http://forwards.github.io/&#34;&gt;Forewards&lt;/a&gt; where R minority users get together to promote R user in under-represented groups.Of course, taking online courses is not enough. I’ve also worked on a couple data science projects using R and Python at work. Some of them are statistical models such as logistic regression, regular regression with seasonality factors. Some of them are just data cleaning tasks which nowadays is a big part of data science, taking about 70-80% of data scientists’ time. At the moment of writing this blog, I’m one month away from my PhD semester begins. Yes, the journey leads to another wonderful world and hopefully you will see another post about my data science experience in academia later.&lt;/p&gt;
&lt;p&gt;List of data science related podcast:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Not So Standard Deviation: by Roger Peng and Hilary Parker&lt;/li&gt;
&lt;li&gt;Data Skeptic: by Kyle Polich&lt;/li&gt;
&lt;li&gt;DataFramed: Data Camp podcast&lt;/li&gt;
&lt;li&gt;Super Data Science: hosted by Kirrill Erimenko-Data Scientist and Lifestyle Entrepreneur&lt;/li&gt;
&lt;li&gt;Linear Digressions: by Ben Jaffe and Katie Malone&lt;/li&gt;
&lt;li&gt;This Week in Machine Learning and Artificial Intelligence&lt;/li&gt;
&lt;li&gt;Learning Machines 101: by Richard Golden&lt;/li&gt;
&lt;li&gt;Data Stories: Enrico Bertini and Moritz Stefaner&lt;/li&gt;
&lt;li&gt;Google Cloud Platform Podcast&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>SIA Career Panel</title>
      <link>https://thinkregressively.netlify.com/talk/sia_talk/</link>
      <pubDate>Sun, 01 Jan 2017 00:00:00 -0500</pubDate>
      
      <guid>https://thinkregressively.netlify.com/talk/sia_talk/</guid>
      <description>&lt;p&gt;Embed your slides or video here using &lt;a href=&#34;https://sourcethemes.com/academic/post/writing-markdown-latex/&#34; target=&#34;_blank&#34;&gt;shortcodes&lt;/a&gt;. Further details can easily be added using &lt;em&gt;Markdown&lt;/em&gt; and $\rm \LaTeX$ math code.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
